{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9c79a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (214, 10)\n",
      "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
      "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
      "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
      "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
      "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
      "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1\n",
      "\n",
      "Class Distribution:\n",
      "Type\n",
      "2    76\n",
      "1    70\n",
      "7    29\n",
      "3    17\n",
      "5    13\n",
      "6     9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "===== Bagging Results =====\n",
      "Accuracy : 0.7441860465116279\n",
      "Precision: 0.7445267910384189\n",
      "Recall   : 0.7441860465116279\n",
      "F1 Score : 0.740761564017378\n",
      "\n",
      "===== Boosting Results =====\n",
      "Accuracy : 0.46511627906976744\n",
      "Precision: 0.4333887043189369\n",
      "Recall   : 0.46511627906976744\n",
      "F1 Score : 0.4181985089573829\n",
      "\n",
      "===== Boosting with Imbalance Handling =====\n",
      "Accuracy : 0.627906976744186\n",
      "F1 Score : 0.6225455378622982\n",
      "\n",
      "===== Model Comparison =====\n",
      "                 Model  F1 Score\n",
      "0              Bagging  0.740762\n",
      "1             Boosting  0.418199\n",
      "2  Boosting (Balanced)  0.622546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 1. Import Libraries\n",
    "# ==============================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# ==============================\n",
    "# 2. Load Dataset\n",
    "# ==============================\n",
    "\n",
    "df = pd.read_excel(\"glass.xlsx\", sheet_name=\"glass\")\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# ==============================\n",
    "# 3. Check Class Imbalance\n",
    "# ==============================\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df[\"Type\"].value_counts())\n",
    "\n",
    "# ==============================\n",
    "# 4. Feature & Target Split\n",
    "# ==============================\n",
    "\n",
    "X = df.drop(\"Type\", axis=1)\n",
    "y = df[\"Type\"]\n",
    "\n",
    "# ==============================\n",
    "# 5. Feature Scaling\n",
    "# ==============================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ==============================\n",
    "# 6. Train-Test Split\n",
    "# ==============================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# 7. BAGGING CLASSIFIER\n",
    "# ==============================\n",
    "\n",
    "bagging_model = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "bagging_model.fit(X_train, y_train)\n",
    "y_pred_bag = bagging_model.predict(X_test)\n",
    "\n",
    "print(\"\\n===== Bagging Results =====\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred_bag))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_bag, average=\"weighted\"))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred_bag, average=\"weighted\"))\n",
    "print(\"F1 Score :\", f1_score(y_test, y_pred_bag, average=\"weighted\"))\n",
    "\n",
    "# ==============================\n",
    "# 8. BOOSTING (AdaBoost)\n",
    "# ==============================\n",
    "\n",
    "boosting_model = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "boosting_model.fit(X_train, y_train)\n",
    "y_pred_boost = boosting_model.predict(X_test)\n",
    "\n",
    "print(\"\\n===== Boosting Results =====\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred_boost))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_boost, average=\"weighted\"))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred_boost, average=\"weighted\"))\n",
    "print(\"F1 Score :\", f1_score(y_test, y_pred_boost, average=\"weighted\"))\n",
    "\n",
    "# ==============================\n",
    "# 9. Handling Imbalanced Data (Class Weight)\n",
    "# ==============================\n",
    "\n",
    "balanced_tree = DecisionTreeClassifier(class_weight=\"balanced\")\n",
    "\n",
    "balanced_boost = AdaBoostClassifier(\n",
    "    estimator=balanced_tree,\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "balanced_boost.fit(X_train, y_train)\n",
    "y_pred_balanced = balanced_boost.predict(X_test)\n",
    "\n",
    "print(\"\\n===== Boosting with Imbalance Handling =====\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred_balanced))\n",
    "print(\"F1 Score :\", f1_score(y_test, y_pred_balanced, average=\"weighted\"))\n",
    "\n",
    "# ==============================\n",
    "# 10. Final Comparison\n",
    "# ==============================\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Bagging\", \"Boosting\", \"Boosting (Balanced)\"],\n",
    "    \"F1 Score\": [\n",
    "        f1_score(y_test, y_pred_bag, average=\"weighted\"),\n",
    "        f1_score(y_test, y_pred_boost, average=\"weighted\"),\n",
    "        f1_score(y_test, y_pred_balanced, average=\"weighted\")\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n===== Model Comparison =====\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ece9805",
   "metadata": {},
   "source": [
    "Interview Question:\n",
    "\n",
    "1. Bagging Vs Boosting:\n",
    "     Bagging reduces variance by training models independently, while Boosting reduces bias by focusing on misclassified samples. Imbalanced data can be handled using class weighting, resampling techniques like SMOTE, and appropriate evaluation metrics.\n",
    "\n",
    "2. Handling Imbalanced Data:\n",
    "    Imbalanced data means some classes have fewer samples than others.\n",
    "\n",
    "    Common Techniques:\n",
    "\n",
    "    1.Class Weighting:\n",
    "      Assigns higher penalty to minority class errors  \n",
    "      Example: class_weight=\"balanced\"\n",
    "\n",
    "    2.Oversampling:\n",
    "       Increase minority class samples\n",
    "       Example: SMOTE\n",
    "\n",
    "    3.Undersampling:\n",
    "       Reduce majority class samples\n",
    "       Use Proper Metrics\n",
    "       Prefer Precision, Recall, F1-score instead of accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220f4cff",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
