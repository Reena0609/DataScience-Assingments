{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f5b6f8c",
   "metadata": {},
   "source": [
    "## ## Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "410b06fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      x_1     x_2     x_3     x_4     x_5     x_6     x_7     x_8     x_9  \\\n",
       " 0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       " 1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       " 2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       " 3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       " 4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       " \n",
       "      x_10  ...    x_52    x_53    x_54    x_55    x_56    x_57    x_58  \\\n",
       " 0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       " 1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       " 2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       " 3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       " 4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       " \n",
       "      x_59    x_60  Y  \n",
       " 0  0.0090  0.0032  R  \n",
       " 1  0.0052  0.0044  R  \n",
       " 2  0.0095  0.0078  R  \n",
       " 3  0.0040  0.0117  R  \n",
       " 4  0.0107  0.0094  R  \n",
       " \n",
       " [5 rows x 61 columns],\n",
       " (208, 61))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"sonardataset.csv\")\n",
    "\n",
    "# Display basic info\n",
    "df.head(), df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48586994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x_1     208 non-null    float64\n",
      " 1   x_2     208 non-null    float64\n",
      " 2   x_3     208 non-null    float64\n",
      " 3   x_4     208 non-null    float64\n",
      " 4   x_5     208 non-null    float64\n",
      " 5   x_6     208 non-null    float64\n",
      " 6   x_7     208 non-null    float64\n",
      " 7   x_8     208 non-null    float64\n",
      " 8   x_9     208 non-null    float64\n",
      " 9   x_10    208 non-null    float64\n",
      " 10  x_11    208 non-null    float64\n",
      " 11  x_12    208 non-null    float64\n",
      " 12  x_13    208 non-null    float64\n",
      " 13  x_14    208 non-null    float64\n",
      " 14  x_15    208 non-null    float64\n",
      " 15  x_16    208 non-null    float64\n",
      " 16  x_17    208 non-null    float64\n",
      " 17  x_18    208 non-null    float64\n",
      " 18  x_19    208 non-null    float64\n",
      " 19  x_20    208 non-null    float64\n",
      " 20  x_21    208 non-null    float64\n",
      " 21  x_22    208 non-null    float64\n",
      " 22  x_23    208 non-null    float64\n",
      " 23  x_24    208 non-null    float64\n",
      " 24  x_25    208 non-null    float64\n",
      " 25  x_26    208 non-null    float64\n",
      " 26  x_27    208 non-null    float64\n",
      " 27  x_28    208 non-null    float64\n",
      " 28  x_29    208 non-null    float64\n",
      " 29  x_30    208 non-null    float64\n",
      " 30  x_31    208 non-null    float64\n",
      " 31  x_32    208 non-null    float64\n",
      " 32  x_33    208 non-null    float64\n",
      " 33  x_34    208 non-null    float64\n",
      " 34  x_35    208 non-null    float64\n",
      " 35  x_36    208 non-null    float64\n",
      " 36  x_37    208 non-null    float64\n",
      " 37  x_38    208 non-null    float64\n",
      " 38  x_39    208 non-null    float64\n",
      " 39  x_40    208 non-null    float64\n",
      " 40  x_41    208 non-null    float64\n",
      " 41  x_42    208 non-null    float64\n",
      " 42  x_43    208 non-null    float64\n",
      " 43  x_44    208 non-null    float64\n",
      " 44  x_45    208 non-null    float64\n",
      " 45  x_46    208 non-null    float64\n",
      " 46  x_47    208 non-null    float64\n",
      " 47  x_48    208 non-null    float64\n",
      " 48  x_49    208 non-null    float64\n",
      " 49  x_50    208 non-null    float64\n",
      " 50  x_51    208 non-null    float64\n",
      " 51  x_52    208 non-null    float64\n",
      " 52  x_53    208 non-null    float64\n",
      " 53  x_54    208 non-null    float64\n",
      " 54  x_55    208 non-null    float64\n",
      " 55  x_56    208 non-null    float64\n",
      " 56  x_57    208 non-null    float64\n",
      " 57  x_58    208 non-null    float64\n",
      " 58  x_59    208 non-null    float64\n",
      " 59  x_60    208 non-null    float64\n",
      " 60  Y       208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>...</th>\n",
       "      <th>x_51</th>\n",
       "      <th>x_52</th>\n",
       "      <th>x_53</th>\n",
       "      <th>x_54</th>\n",
       "      <th>x_55</th>\n",
       "      <th>x_56</th>\n",
       "      <th>x_57</th>\n",
       "      <th>x_58</th>\n",
       "      <th>x_59</th>\n",
       "      <th>x_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x_1         x_2         x_3         x_4         x_5         x_6  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "              x_7         x_8         x_9        x_10  ...        x_51  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "             x_52        x_53        x_54        x_55        x_56        x_57  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "             x_58        x_59        x_60  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca9be192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_6', 'x_7', 'x_8', 'x_9', 'x_10',\n",
      "       'x_11', 'x_12', 'x_13', 'x_14', 'x_15', 'x_16', 'x_17', 'x_18', 'x_19',\n",
      "       'x_20', 'x_21', 'x_22', 'x_23', 'x_24', 'x_25', 'x_26', 'x_27', 'x_28',\n",
      "       'x_29', 'x_30', 'x_31', 'x_32', 'x_33', 'x_34', 'x_35', 'x_36', 'x_37',\n",
      "       'x_38', 'x_39', 'x_40', 'x_41', 'x_42', 'x_43', 'x_44', 'x_45', 'x_46',\n",
      "       'x_47', 'x_48', 'x_49', 'x_50', 'x_51', 'x_52', 'x_53', 'x_54', 'x_55',\n",
      "       'x_56', 'x_57', 'x_58', 'x_59', 'x_60', 'Y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc5ac402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R' 'M']\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[:, -1].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "031fc3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={df.columns[-1]: 'Class'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f4011ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df['Class'] = LabelEncoder().fit_transform(df['Class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edbf16fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b83e3d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    111\n",
      "1     97\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eebbbd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de4e742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e13ccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84a91be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                976       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,121\n",
      "Trainable params: 1,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(60,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3adaf4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 20ms/step - loss: 0.8220 - accuracy: 0.4765 - val_loss: 0.7942 - val_accuracy: 0.3529\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7340 - accuracy: 0.5638 - val_loss: 0.7686 - val_accuracy: 0.4118\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6686 - accuracy: 0.6242 - val_loss: 0.7567 - val_accuracy: 0.4118\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6195 - accuracy: 0.6577 - val_loss: 0.7405 - val_accuracy: 0.4118\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.7450 - val_loss: 0.7269 - val_accuracy: 0.5294\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5392 - accuracy: 0.7651 - val_loss: 0.7164 - val_accuracy: 0.5294\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7651 - val_loss: 0.7053 - val_accuracy: 0.5882\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7919 - val_loss: 0.6917 - val_accuracy: 0.5882\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.8121 - val_loss: 0.6823 - val_accuracy: 0.5882\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.8255 - val_loss: 0.6730 - val_accuracy: 0.5882\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.8389 - val_loss: 0.6667 - val_accuracy: 0.5882\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8658 - val_loss: 0.6603 - val_accuracy: 0.5882\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3613 - accuracy: 0.8792 - val_loss: 0.6533 - val_accuracy: 0.5882\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3456 - accuracy: 0.8859 - val_loss: 0.6482 - val_accuracy: 0.6471\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3282 - accuracy: 0.8926 - val_loss: 0.6436 - val_accuracy: 0.6471\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3134 - accuracy: 0.8926 - val_loss: 0.6361 - val_accuracy: 0.6471\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2993 - accuracy: 0.8993 - val_loss: 0.6367 - val_accuracy: 0.6471\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2875 - accuracy: 0.9060 - val_loss: 0.6328 - val_accuracy: 0.6471\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2750 - accuracy: 0.9262 - val_loss: 0.6240 - val_accuracy: 0.6471\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2644 - accuracy: 0.9329 - val_loss: 0.6274 - val_accuracy: 0.6471\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2552 - accuracy: 0.9262 - val_loss: 0.6331 - val_accuracy: 0.6471\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2444 - accuracy: 0.9396 - val_loss: 0.6349 - val_accuracy: 0.6471\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2355 - accuracy: 0.9463 - val_loss: 0.6479 - val_accuracy: 0.5882\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2259 - accuracy: 0.9463 - val_loss: 0.6533 - val_accuracy: 0.5882\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2169 - accuracy: 0.9463 - val_loss: 0.6522 - val_accuracy: 0.5882\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2083 - accuracy: 0.9463 - val_loss: 0.6540 - val_accuracy: 0.5882\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1998 - accuracy: 0.9530 - val_loss: 0.6643 - val_accuracy: 0.5882\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1925 - accuracy: 0.9597 - val_loss: 0.6666 - val_accuracy: 0.5882\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1845 - accuracy: 0.9597 - val_loss: 0.6714 - val_accuracy: 0.5882\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1778 - accuracy: 0.9530 - val_loss: 0.6722 - val_accuracy: 0.5882\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1712 - accuracy: 0.9664 - val_loss: 0.6715 - val_accuracy: 0.5882\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1646 - accuracy: 0.9597 - val_loss: 0.6843 - val_accuracy: 0.5882\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1585 - accuracy: 0.9597 - val_loss: 0.6863 - val_accuracy: 0.5882\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1528 - accuracy: 0.9664 - val_loss: 0.6947 - val_accuracy: 0.5882\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9597 - val_loss: 0.6940 - val_accuracy: 0.5882\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1412 - accuracy: 0.9664 - val_loss: 0.7052 - val_accuracy: 0.5882\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1355 - accuracy: 0.9597 - val_loss: 0.7029 - val_accuracy: 0.5882\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1304 - accuracy: 0.9664 - val_loss: 0.7045 - val_accuracy: 0.5882\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.9597 - val_loss: 0.7164 - val_accuracy: 0.5882\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1204 - accuracy: 0.9664 - val_loss: 0.7244 - val_accuracy: 0.5882\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1159 - accuracy: 0.9664 - val_loss: 0.7264 - val_accuracy: 0.5882\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1123 - accuracy: 0.9664 - val_loss: 0.7372 - val_accuracy: 0.5882\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1078 - accuracy: 0.9664 - val_loss: 0.7216 - val_accuracy: 0.5882\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1045 - accuracy: 0.9664 - val_loss: 0.7256 - val_accuracy: 0.5882\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1002 - accuracy: 0.9732 - val_loss: 0.7327 - val_accuracy: 0.5882\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0966 - accuracy: 0.9732 - val_loss: 0.7473 - val_accuracy: 0.5882\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0931 - accuracy: 0.9866 - val_loss: 0.7592 - val_accuracy: 0.5882\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0893 - accuracy: 0.9866 - val_loss: 0.7464 - val_accuracy: 0.5882\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0861 - accuracy: 0.9866 - val_loss: 0.7501 - val_accuracy: 0.5882\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0826 - accuracy: 0.9933 - val_loss: 0.7571 - val_accuracy: 0.5882\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0795 - accuracy: 0.9933 - val_loss: 0.7731 - val_accuracy: 0.5882\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 0.7810 - val_accuracy: 0.5882\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.7852 - val_accuracy: 0.5882\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.9933 - val_loss: 0.7874 - val_accuracy: 0.5882\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.7726 - val_accuracy: 0.5882\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.7781 - val_accuracy: 0.5882\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.7914 - val_accuracy: 0.5882\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.7981 - val_accuracy: 0.5882\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.8000 - val_accuracy: 0.5882\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.8053 - val_accuracy: 0.5882\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.8099 - val_accuracy: 0.5882\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.8102 - val_accuracy: 0.5882\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.7933 - val_accuracy: 0.5882\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.7923 - val_accuracy: 0.5882\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.5882\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.8190 - val_accuracy: 0.5882\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.8328 - val_accuracy: 0.5882\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.8321 - val_accuracy: 0.5882\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.8310 - val_accuracy: 0.5882\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.8350 - val_accuracy: 0.5882\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.8402 - val_accuracy: 0.5882\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.8384 - val_accuracy: 0.5882\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.8445 - val_accuracy: 0.5882\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.8309 - val_accuracy: 0.5882\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.8307 - val_accuracy: 0.5882\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.8480 - val_accuracy: 0.5882\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.8530 - val_accuracy: 0.5882\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.8609 - val_accuracy: 0.5882\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.8651 - val_accuracy: 0.5882\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.8703 - val_accuracy: 0.5882\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.8615 - val_accuracy: 0.5882\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.8640 - val_accuracy: 0.5882\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.8757 - val_accuracy: 0.5882\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.8745 - val_accuracy: 0.5882\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.8656 - val_accuracy: 0.5882\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.8741 - val_accuracy: 0.5882\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.8834 - val_accuracy: 0.5882\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.8722 - val_accuracy: 0.5882\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.8774 - val_accuracy: 0.5882\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.8867 - val_accuracy: 0.5882\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.8915 - val_accuracy: 0.5882\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.9050 - val_accuracy: 0.5882\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.9289 - val_accuracy: 0.5882\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.9363 - val_accuracy: 0.5882\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.9372 - val_accuracy: 0.5882\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.9320 - val_accuracy: 0.5882\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.9375 - val_accuracy: 0.5882\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.9463 - val_accuracy: 0.5882\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.9491 - val_accuracy: 0.5882\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.9411 - val_accuracy: 0.5882\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8d0c14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "19/19 [==============================] - 1s 8ms/step - loss: 0.7025 - accuracy: 0.4966 - val_loss: 0.6927 - val_accuracy: 0.5882\n",
      "Epoch 2/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.6980 - val_loss: 0.6842 - val_accuracy: 0.5882\n",
      "Epoch 3/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.8121 - val_loss: 0.6791 - val_accuracy: 0.5294\n",
      "Epoch 4/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.8725 - val_loss: 0.6651 - val_accuracy: 0.5882\n",
      "Epoch 5/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.9195 - val_loss: 0.6499 - val_accuracy: 0.5294\n",
      "Epoch 6/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3876 - accuracy: 0.9329 - val_loss: 0.6373 - val_accuracy: 0.5294\n",
      "Epoch 7/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.9262 - val_loss: 0.6212 - val_accuracy: 0.5882\n",
      "Epoch 8/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2727 - accuracy: 0.9262 - val_loss: 0.6100 - val_accuracy: 0.5294\n",
      "Epoch 9/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2317 - accuracy: 0.9530 - val_loss: 0.6115 - val_accuracy: 0.5294\n",
      "Epoch 10/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2016 - accuracy: 0.9597 - val_loss: 0.5981 - val_accuracy: 0.5294\n",
      "Epoch 11/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1726 - accuracy: 0.9732 - val_loss: 0.6100 - val_accuracy: 0.5882\n",
      "Epoch 12/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1512 - accuracy: 0.9664 - val_loss: 0.6018 - val_accuracy: 0.6471\n",
      "Epoch 13/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.9732 - val_loss: 0.5807 - val_accuracy: 0.6471\n",
      "Epoch 14/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1147 - accuracy: 0.9732 - val_loss: 0.5453 - val_accuracy: 0.6471\n",
      "Epoch 15/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9799 - val_loss: 0.5561 - val_accuracy: 0.6471\n",
      "Epoch 16/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0865 - accuracy: 0.9933 - val_loss: 0.5404 - val_accuracy: 0.6471\n",
      "Epoch 17/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0745 - accuracy: 0.9933 - val_loss: 0.5527 - val_accuracy: 0.7059\n",
      "Epoch 18/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.9933 - val_loss: 0.5512 - val_accuracy: 0.7059\n",
      "Epoch 19/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9933 - val_loss: 0.5616 - val_accuracy: 0.7059\n",
      "Epoch 20/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 0.9933 - val_loss: 0.5703 - val_accuracy: 0.7647\n",
      "Epoch 21/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9933 - val_loss: 0.5400 - val_accuracy: 0.7647\n",
      "Epoch 22/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9933 - val_loss: 0.5760 - val_accuracy: 0.7647\n",
      "Epoch 23/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9933 - val_loss: 0.5578 - val_accuracy: 0.7647\n",
      "Epoch 24/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9933 - val_loss: 0.5798 - val_accuracy: 0.7647\n",
      "Epoch 25/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9933 - val_loss: 0.5925 - val_accuracy: 0.7647\n",
      "Epoch 26/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.6129 - val_accuracy: 0.7647\n",
      "Epoch 27/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.6117 - val_accuracy: 0.7647\n",
      "Epoch 28/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.6215 - val_accuracy: 0.7647\n",
      "Epoch 29/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9933 - val_loss: 0.6353 - val_accuracy: 0.7647\n",
      "Epoch 30/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.9933 - val_loss: 0.6250 - val_accuracy: 0.7647\n",
      "Epoch 31/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.6471 - val_accuracy: 0.7647\n",
      "Epoch 32/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.6249 - val_accuracy: 0.7647\n",
      "Epoch 33/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.6498 - val_accuracy: 0.7647\n",
      "Epoch 34/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.6830 - val_accuracy: 0.7647\n",
      "Epoch 35/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.6917 - val_accuracy: 0.7647\n",
      "Epoch 36/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.7222 - val_accuracy: 0.7647\n",
      "Epoch 37/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.7364 - val_accuracy: 0.7647\n",
      "Epoch 38/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.7683 - val_accuracy: 0.7647\n",
      "Epoch 39/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.7896 - val_accuracy: 0.7647\n",
      "Epoch 40/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8018 - val_accuracy: 0.7647\n",
      "Epoch 41/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8185 - val_accuracy: 0.7647\n",
      "Epoch 42/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8376 - val_accuracy: 0.7647\n",
      "Epoch 43/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8419 - val_accuracy: 0.7647\n",
      "Epoch 44/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8615 - val_accuracy: 0.7647\n",
      "Epoch 45/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8746 - val_accuracy: 0.7647\n",
      "Epoch 46/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8767 - val_accuracy: 0.7647\n",
      "Epoch 47/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8867 - val_accuracy: 0.7647\n",
      "Epoch 48/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8995 - val_accuracy: 0.7647\n",
      "Epoch 49/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9052 - val_accuracy: 0.7647\n",
      "Epoch 50/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9259 - val_accuracy: 0.7647\n",
      "Epoch 51/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9217 - val_accuracy: 0.7647\n",
      "Epoch 52/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9424 - val_accuracy: 0.7647\n",
      "Epoch 53/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9518 - val_accuracy: 0.7647\n",
      "Epoch 54/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9562 - val_accuracy: 0.7647\n",
      "Epoch 55/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9738 - val_accuracy: 0.7647\n",
      "Epoch 56/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9707 - val_accuracy: 0.7647\n",
      "Epoch 57/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9784 - val_accuracy: 0.7647\n",
      "Epoch 58/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9926 - val_accuracy: 0.7647\n",
      "Epoch 59/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9999 - val_accuracy: 0.7647\n",
      "Epoch 60/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0100 - val_accuracy: 0.7647\n",
      "Epoch 61/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0178 - val_accuracy: 0.7647\n",
      "Epoch 62/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0285 - val_accuracy: 0.7647\n",
      "Epoch 63/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0301 - val_accuracy: 0.7647\n",
      "Epoch 64/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0448 - val_accuracy: 0.7647\n",
      "Epoch 65/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0494 - val_accuracy: 0.7647\n",
      "Epoch 66/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 9.8164e-04 - accuracy: 1.0000 - val_loss: 1.0561 - val_accuracy: 0.7647\n",
      "Epoch 67/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 9.3791e-04 - accuracy: 1.0000 - val_loss: 1.0632 - val_accuracy: 0.7647\n",
      "Epoch 68/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 8.9724e-04 - accuracy: 1.0000 - val_loss: 1.0684 - val_accuracy: 0.7647\n",
      "Epoch 69/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 8.6437e-04 - accuracy: 1.0000 - val_loss: 1.0755 - val_accuracy: 0.7647\n",
      "Epoch 70/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 8.2969e-04 - accuracy: 1.0000 - val_loss: 1.0890 - val_accuracy: 0.7647\n",
      "Epoch 71/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7.9653e-04 - accuracy: 1.0000 - val_loss: 1.0935 - val_accuracy: 0.7647\n",
      "Epoch 72/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7.6532e-04 - accuracy: 1.0000 - val_loss: 1.0987 - val_accuracy: 0.7647\n",
      "Epoch 73/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7.3718e-04 - accuracy: 1.0000 - val_loss: 1.1123 - val_accuracy: 0.7647\n",
      "Epoch 74/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7.1009e-04 - accuracy: 1.0000 - val_loss: 1.1087 - val_accuracy: 0.7647\n",
      "Epoch 75/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 6.8266e-04 - accuracy: 1.0000 - val_loss: 1.1180 - val_accuracy: 0.7647\n",
      "Epoch 76/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.5900e-04 - accuracy: 1.0000 - val_loss: 1.1276 - val_accuracy: 0.7647\n",
      "Epoch 77/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 6.3533e-04 - accuracy: 1.0000 - val_loss: 1.1317 - val_accuracy: 0.7647\n",
      "Epoch 78/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 6.1474e-04 - accuracy: 1.0000 - val_loss: 1.1393 - val_accuracy: 0.7647\n",
      "Epoch 79/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 5.9175e-04 - accuracy: 1.0000 - val_loss: 1.1457 - val_accuracy: 0.7647\n",
      "Epoch 80/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 5.7101e-04 - accuracy: 1.0000 - val_loss: 1.1515 - val_accuracy: 0.7647\n",
      "Epoch 81/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 5.5149e-04 - accuracy: 1.0000 - val_loss: 1.1540 - val_accuracy: 0.7647\n",
      "Epoch 82/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.3299e-04 - accuracy: 1.0000 - val_loss: 1.1625 - val_accuracy: 0.7647\n",
      "Epoch 83/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 5.1588e-04 - accuracy: 1.0000 - val_loss: 1.1695 - val_accuracy: 0.7647\n",
      "Epoch 84/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4.9962e-04 - accuracy: 1.0000 - val_loss: 1.1740 - val_accuracy: 0.7647\n",
      "Epoch 85/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4.8286e-04 - accuracy: 1.0000 - val_loss: 1.1793 - val_accuracy: 0.7647\n",
      "Epoch 86/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4.6876e-04 - accuracy: 1.0000 - val_loss: 1.1852 - val_accuracy: 0.7647\n",
      "Epoch 87/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4.5406e-04 - accuracy: 1.0000 - val_loss: 1.1894 - val_accuracy: 0.7647\n",
      "Epoch 88/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4.4094e-04 - accuracy: 1.0000 - val_loss: 1.1958 - val_accuracy: 0.7647\n",
      "Epoch 89/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4.2672e-04 - accuracy: 1.0000 - val_loss: 1.1970 - val_accuracy: 0.7647\n",
      "Epoch 90/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4.1461e-04 - accuracy: 1.0000 - val_loss: 1.2026 - val_accuracy: 0.7647\n",
      "Epoch 91/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4.0217e-04 - accuracy: 1.0000 - val_loss: 1.2093 - val_accuracy: 0.7647\n",
      "Epoch 92/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.9107e-04 - accuracy: 1.0000 - val_loss: 1.2116 - val_accuracy: 0.7647\n",
      "Epoch 93/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.7933e-04 - accuracy: 1.0000 - val_loss: 1.2191 - val_accuracy: 0.7647\n",
      "Epoch 94/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.6860e-04 - accuracy: 1.0000 - val_loss: 1.2246 - val_accuracy: 0.7647\n",
      "Epoch 95/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.5765e-04 - accuracy: 1.0000 - val_loss: 1.2282 - val_accuracy: 0.7647\n",
      "Epoch 96/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.4856e-04 - accuracy: 1.0000 - val_loss: 1.2360 - val_accuracy: 0.7647\n",
      "Epoch 97/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.3829e-04 - accuracy: 1.0000 - val_loss: 1.2382 - val_accuracy: 0.7647\n",
      "Epoch 98/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.2991e-04 - accuracy: 1.0000 - val_loss: 1.2476 - val_accuracy: 0.7059\n",
      "Epoch 99/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.1972e-04 - accuracy: 1.0000 - val_loss: 1.2498 - val_accuracy: 0.7647\n",
      "Epoch 100/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.1105e-04 - accuracy: 1.0000 - val_loss: 1.2541 - val_accuracy: 0.7647\n",
      "Epoch 101/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.0319e-04 - accuracy: 1.0000 - val_loss: 1.2531 - val_accuracy: 0.7647\n",
      "Epoch 102/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.9420e-04 - accuracy: 1.0000 - val_loss: 1.2591 - val_accuracy: 0.7647\n",
      "Epoch 103/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.8620e-04 - accuracy: 1.0000 - val_loss: 1.2686 - val_accuracy: 0.7059\n",
      "Epoch 104/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.7892e-04 - accuracy: 1.0000 - val_loss: 1.2781 - val_accuracy: 0.7059\n",
      "Epoch 105/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.7070e-04 - accuracy: 1.0000 - val_loss: 1.2735 - val_accuracy: 0.7059\n",
      "Epoch 106/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.6433e-04 - accuracy: 1.0000 - val_loss: 1.2799 - val_accuracy: 0.7059\n",
      "Epoch 107/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.5776e-04 - accuracy: 1.0000 - val_loss: 1.2860 - val_accuracy: 0.7059\n",
      "Epoch 108/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.5047e-04 - accuracy: 1.0000 - val_loss: 1.2916 - val_accuracy: 0.7059\n",
      "Epoch 109/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.4407e-04 - accuracy: 1.0000 - val_loss: 1.2898 - val_accuracy: 0.7059\n",
      "Epoch 110/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.3799e-04 - accuracy: 1.0000 - val_loss: 1.2978 - val_accuracy: 0.7059\n",
      "Epoch 111/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.3183e-04 - accuracy: 1.0000 - val_loss: 1.3048 - val_accuracy: 0.7059\n",
      "Epoch 112/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.2648e-04 - accuracy: 1.0000 - val_loss: 1.3091 - val_accuracy: 0.7059\n",
      "Epoch 113/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.2095e-04 - accuracy: 1.0000 - val_loss: 1.3073 - val_accuracy: 0.7059\n",
      "Epoch 114/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.1555e-04 - accuracy: 1.0000 - val_loss: 1.3166 - val_accuracy: 0.7059\n",
      "Epoch 115/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.1009e-04 - accuracy: 1.0000 - val_loss: 1.3209 - val_accuracy: 0.7059\n",
      "Epoch 116/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.0532e-04 - accuracy: 1.0000 - val_loss: 1.3224 - val_accuracy: 0.7059\n",
      "Epoch 117/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.0064e-04 - accuracy: 1.0000 - val_loss: 1.3282 - val_accuracy: 0.7059\n",
      "Epoch 118/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.9566e-04 - accuracy: 1.0000 - val_loss: 1.3321 - val_accuracy: 0.7059\n",
      "Epoch 119/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.9152e-04 - accuracy: 1.0000 - val_loss: 1.3398 - val_accuracy: 0.7059\n",
      "Epoch 120/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.8684e-04 - accuracy: 1.0000 - val_loss: 1.3397 - val_accuracy: 0.7059\n",
      "Epoch 121/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.8265e-04 - accuracy: 1.0000 - val_loss: 1.3447 - val_accuracy: 0.7059\n",
      "Epoch 122/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.7846e-04 - accuracy: 1.0000 - val_loss: 1.3512 - val_accuracy: 0.7059\n",
      "Epoch 123/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.7457e-04 - accuracy: 1.0000 - val_loss: 1.3528 - val_accuracy: 0.7059\n",
      "Epoch 124/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.7083e-04 - accuracy: 1.0000 - val_loss: 1.3569 - val_accuracy: 0.7059\n",
      "Epoch 125/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.6696e-04 - accuracy: 1.0000 - val_loss: 1.3630 - val_accuracy: 0.7059\n",
      "Epoch 126/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.6325e-04 - accuracy: 1.0000 - val_loss: 1.3687 - val_accuracy: 0.7059\n",
      "Epoch 127/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.5982e-04 - accuracy: 1.0000 - val_loss: 1.3739 - val_accuracy: 0.7059\n",
      "Epoch 128/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.5675e-04 - accuracy: 1.0000 - val_loss: 1.3715 - val_accuracy: 0.7059\n",
      "Epoch 129/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.5300e-04 - accuracy: 1.0000 - val_loss: 1.3775 - val_accuracy: 0.7059\n",
      "Epoch 130/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.4991e-04 - accuracy: 1.0000 - val_loss: 1.3833 - val_accuracy: 0.7059\n",
      "Epoch 131/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.4674e-04 - accuracy: 1.0000 - val_loss: 1.3853 - val_accuracy: 0.7059\n",
      "Epoch 132/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.4393e-04 - accuracy: 1.0000 - val_loss: 1.3879 - val_accuracy: 0.7059\n",
      "Epoch 133/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.4059e-04 - accuracy: 1.0000 - val_loss: 1.3941 - val_accuracy: 0.7059\n",
      "Epoch 134/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.3807e-04 - accuracy: 1.0000 - val_loss: 1.3969 - val_accuracy: 0.7059\n",
      "Epoch 135/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.3498e-04 - accuracy: 1.0000 - val_loss: 1.3998 - val_accuracy: 0.7059\n",
      "Epoch 136/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.3229e-04 - accuracy: 1.0000 - val_loss: 1.4055 - val_accuracy: 0.7059\n",
      "Epoch 137/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.2952e-04 - accuracy: 1.0000 - val_loss: 1.4081 - val_accuracy: 0.7059\n",
      "Epoch 138/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.2693e-04 - accuracy: 1.0000 - val_loss: 1.4109 - val_accuracy: 0.7059\n",
      "Epoch 139/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.2444e-04 - accuracy: 1.0000 - val_loss: 1.4186 - val_accuracy: 0.7059\n",
      "Epoch 140/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.2203e-04 - accuracy: 1.0000 - val_loss: 1.4199 - val_accuracy: 0.7059\n",
      "Epoch 141/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.1968e-04 - accuracy: 1.0000 - val_loss: 1.4228 - val_accuracy: 0.7059\n",
      "Epoch 142/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.1738e-04 - accuracy: 1.0000 - val_loss: 1.4279 - val_accuracy: 0.7059\n",
      "Epoch 143/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.1500e-04 - accuracy: 1.0000 - val_loss: 1.4312 - val_accuracy: 0.7059\n",
      "Epoch 144/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.1282e-04 - accuracy: 1.0000 - val_loss: 1.4331 - val_accuracy: 0.7059\n",
      "Epoch 145/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.1082e-04 - accuracy: 1.0000 - val_loss: 1.4378 - val_accuracy: 0.7059\n",
      "Epoch 146/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.0864e-04 - accuracy: 1.0000 - val_loss: 1.4388 - val_accuracy: 0.7059\n",
      "Epoch 147/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.0647e-04 - accuracy: 1.0000 - val_loss: 1.4460 - val_accuracy: 0.7059\n",
      "Epoch 148/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.0448e-04 - accuracy: 1.0000 - val_loss: 1.4500 - val_accuracy: 0.7059\n",
      "Epoch 149/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.0259e-04 - accuracy: 1.0000 - val_loss: 1.4528 - val_accuracy: 0.7059\n",
      "Epoch 150/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.0060e-04 - accuracy: 1.0000 - val_loss: 1.4559 - val_accuracy: 0.7059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d3b1e40760>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "tuned_model = Sequential()\n",
    "tuned_model.add(Dense(32, activation='relu', input_shape=(60,)))\n",
    "tuned_model.add(Dense(16, activation='relu'))\n",
    "tuned_model.add(Dense(8, activation='relu'))\n",
    "tuned_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "tuned_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "tuned_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=150,\n",
    "    batch_size=8,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3e33a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_pred = (tuned_model.predict(X_test) > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca0b91ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8095238095238095\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84        26\n",
      "           1       0.72      0.81      0.76        16\n",
      "\n",
      "    accuracy                           0.81        42\n",
      "   macro avg       0.80      0.81      0.80        42\n",
      "weighted avg       0.82      0.81      0.81        42\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[21  5]\n",
      " [ 3 13]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
